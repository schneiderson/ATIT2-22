{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgINZ0ugNRakJgkyg91clk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJOywxU7vtMv"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1lr1zjdLym"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8emMOB-uvxwL"
      },
      "source": [
        "## Task\n",
        "Your task is to do a linear regression on the car-price dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zm6SPEdfur-"
      },
      "source": [
        "cars = pd.read_csv('https://raw.githubusercontent.com/schneiderson/ATIT2-21/master/sample_data/CarPrice_Assignment.csv')\n",
        "cars.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GPYH63TgsKU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In linear regression an attribute is a good predictor if there is a correlation between the independent variable (x: some attribute of the car) and the independent variable (y: car price).\n",
        "\n",
        "Check which numeric attributes have a positive correlation with the car price. To achieve this you can either plot the graph and check the correlation visually (using the scatter function) or you can use pandas corr() function.\n",
        "\n",
        "(optional: you can print the correlation matrix with a heatmap from the seaborn library. sns.heatmap(df, annot=True))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KbFfhsgY7O"
      },
      "source": [
        "def scatter(column):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(cars[column], cars['price'])\n",
        "    plt.title(column+' vs Price')\n",
        "    plt.ylabel('Price')\n",
        "    plt.xlabel(column)\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlYu7ZDrjSFG"
      },
      "source": [
        "## Data exploration\n",
        "Plot the four attributes with the highest positive correlation to the price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rd45sbngY92"
      },
      "source": [
        "# plot the four attributes with highest correlation\n",
        "# scatter(\"colum_name\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ9vYnakjlPX"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Use one of the attributes with the highest correlation and train a linear regression model.\n",
        "\n",
        "Before training, split the dataset in training and test data. (80%, 20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOJJI79CgZAO"
      },
      "source": [
        "# use train_test_split method from sklearn.model_selection library to split data in training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(0) # setting the seed will make the \"random\" split deterministic (more reliable and comparable results)\n",
        "\n",
        "# hint: it should look something like this:\n",
        "# df_train, df_test = train_test_split(<?>, train_size = 0.8, test_size = 0.2, random_state = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr2mpYArk7Vr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Do feature scaling on the numerical independant variables for both the training dataset and the test dataset.\n",
        "\n",
        "Use fit_transform() on the training dataset and transform() on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7FQMO8LgZCu"
      },
      "source": [
        "# use MinMaxScaler from sklearn.preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# scaler.fit_transform(<training_data>)\n",
        "# scaler.transform(<test_data>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJN_yMytQaK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Can you explain why you should not use fit_transform on both datasets? (Hint: think about what training and test data represent if you train a model to solve a real problem where future predictions are made on unseen data.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSeC87wtUT1"
      },
      "source": [
        "--> your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LajtIUXPmLoC"
      },
      "source": [
        "## Model training\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Train a linear regression model on the training data. Use the attribute which you have identified has the highest correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GK5x7CvgZFO"
      },
      "source": [
        "# use LinearRegression class from sklearn_linear_model \n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression()\n",
        "\n",
        "# we need to reshape the array because sklearn LinearRegression expects arrays in the shape of (n, f), \n",
        "# where f is the number of features we want to train on.\n",
        "x_train = df_train['<column_name?>'].values.reshape(-1, 1)\n",
        "y_train = df_train['price'].values.reshape(-1, 1)\n",
        "\n",
        "lm.fit(<x>, <y>)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzcUJ0QfluZH"
      },
      "source": [
        "## Predictions\n",
        "Make predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAtVtFtagZHo"
      },
      "source": [
        "# reshape the test data just as you've done it above with the test data\n",
        "x_test = \n",
        "y_test =\n",
        "\n",
        "# then pass the data to the linear regression model to make predictions\n",
        "y_predicted = lm.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8whcc3IqLhT"
      },
      "source": [
        "(optional: use a goodness of fit metric like r2_score to check how good the regression is)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkOSAa1kl-d2"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-0iF5WotCX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Plot true values and calculated regression line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNoIeIvinFrm"
      },
      "source": [
        "plt.scatter(x_test, y_test, color='black')\n",
        "plt.plot(x_test, y_predicted, color='blue', linewidth=3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iCh5wKYvoer"
      },
      "source": [
        "# Logistic regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtGjR-Ymwazh"
      },
      "source": [
        "## Task\n",
        "This dataset contains purchase information based on Gender, Age and Estmiated-salary. Your task is to use logistic regression and find out which feature is best to predict if an individual has bought the product or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Cfmc2fyXvh"
      },
      "source": [
        "df_ads = pd.read_csv('https://raw.githubusercontent.com/schneiderson/ATIT2-21/master/sample_data/Social_Network_Ads.csv')\n",
        "df_ads.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgjiyNJV35aX"
      },
      "source": [
        "## Data Preparation\n",
        "First we encode the Gender feature. At this point the feature is a column containing texts either \"Male\" ore \"Female\". What we want is a numerical feature. Hence, we can use a Label Encoder to transform the column to a binary encoded column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ2yF3JxzSd_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df_ads['Gender'] = le.fit_transform(df_ads['Gender'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6jBnwbJ4PyR"
      },
      "source": [
        "Do a train test split, just like in the previous task. (80/20 train/test split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzIDD06Y0Qeq"
      },
      "source": [
        "# do a train test split like in the previous task\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8DpLkcj4ZHa"
      },
      "source": [
        "Do feature scaling for the columns \"Age\" and \"EstimatedSalary\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6azIi6Lgyr4s"
      },
      "source": [
        "scaler2 = MinMaxScaler()\n",
        "# do feature scaling like in the previous task\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHLdcK8a4i9V"
      },
      "source": [
        "## Model training\n",
        "Fit the LogisticRegression model to the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvRRdVu0u53"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# we need to reshape the array because sklearn LogisticRegression expects arrays in the shape of (n, f), \n",
        "# where f is the number of features we want to train on. (Check the previous task for reference)\n",
        "x_ads_train = \n",
        "y_ads_train = \n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_ads_train, y_ads_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmxXscLn4sms"
      },
      "source": [
        "## Predictions and model evaluation\n",
        "Evaluate the accuracy, precision and recall metrics on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCAxO7692hAP"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "x_ads_test = \n",
        "y_ads_test = \n",
        "\n",
        "y_ads_predictions = logreg.predict(x_ads_test) # generate predictions\n",
        "\n",
        "print('Accuracy: {}'.format(accuracy_score(y_ads_test, y_ads_predictions)))\n",
        "print('Precision: {}'.format(precision_score(y_ads_test, y_ads_predictions)))\n",
        "print('Recall: {}'.format(recall_score(y_ads_test, y_ads_predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjXmHJTb-uXp"
      },
      "source": [
        "Based on these three metrics, try to discuss which result is best under which circumstances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ-arut3-9uj"
      },
      "source": [
        "--> your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoU-01h273ze"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall from the lecture: We can do linear and logistic regression on multiple features. \n",
        "\n",
        "Deos the performance of the logistic regression model improve if you use a combination of several features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slmTD5b_8tEP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
