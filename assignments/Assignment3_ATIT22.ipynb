{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/QWXwhLMAtu5vnne1lBQd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S14s9ADHS9w"
      },
      "source": [
        "# Assignment 3 (Part 1)\n",
        "\n",
        "Part 1 of the third assignment is worth 25 points.\n",
        "\n",
        "## Neural Networks\n",
        "\n",
        "Also known as Multi-Layer-Perceptrons (MLP). Hence for this assignment you will use the MLPClassifier class from Sklearn. \n",
        "\n",
        "Take a look at the documentation to learn more about the default parameterisation (which activation function it uses, which optimizer/solver it uses, number and size of hidden layers, etc.) of the MLPClassifer: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html. \n",
        "\n",
        "\n",
        "This parctical part of the assignment is devided in 2 main tasks:\n",
        "\n",
        "\n",
        "*   Training a neural network on MNIST data (5 points)\n",
        "*   Training a neural networks on customer data (20 points)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFFVKTWQJeWd"
      },
      "source": [
        "### Task 1: Neural Network Classifier on MNIST "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzWI6gk3JdEI"
      },
      "source": [
        "# load required libraries\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM8DvF5fJ5Np"
      },
      "source": [
        "The task will be to perform classification on handwritten digits from 0 to 9 (MNIST dataset). (We've seen this dataset in the previous assignment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChOOL3YeJqto"
      },
      "source": [
        "# download dataset from https://www.openml.org/ which contains many sample datasets for machine learning\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cuKVOZmJuAM"
      },
      "source": [
        "**Recap**: The dataset contains 70000 examples of which each example has 784 values (pixels). These pixels are in a flat array but represent a 28 by 28 pixel gray-scale image. Values range from 0 to 255 which is common in the RGB value range. A value of 0 represents a black pixel whereas 255 represents a white pixel. Different shades of gray are any value larger than 0 but smaller than 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbIjxFuxO56N"
      },
      "source": [
        "# if we want to plot a single example we need to reshape the array\n",
        "first_image = np.array(<IMAGE>, dtype='float').reshape((28, 28))\n",
        "plt.imshow(first_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B9x73V-HTQV"
      },
      "source": [
        "#### Instructions\n",
        "\n",
        "**You are expected to do:**\n",
        "\n",
        "\n",
        "*   Data preparation: \n",
        " *   Perform a 80/20 train/test split\n",
        " *   Perform feature scaling\n",
        "*   Train the model\n",
        " *   Please use `MLPClassifier` from `sklearn.neural_network`\n",
        "*   Evaluate the model performance\n",
        " *   Calculate the accuracy\n",
        " *   Plot the confusion matrix\n",
        " *   Additionally, plot some misclassified instances  (if there are any). You can use the plt.imshow() function as shown above\n",
        "* Compare the model performance with the results of the softmax regression on MNIST in the previous assignment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_mQ_OPLFmP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFSHAlcLFbu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMuxvInJLFTZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ODadjEdHTVE"
      },
      "source": [
        "### Task 2: neural network classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aoa13hkLTvC"
      },
      "source": [
        "# load required libraries\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pll7ms5wYPHg"
      },
      "source": [
        "#### Dataset \n",
        "\n",
        "This is a classic marketing bank dataset uploaded originally in the UCI Machine Learning Repository and contains >41k records. You can find more information about the features (attributes) on the official UCI website:\n",
        "https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
        "\n",
        "The dataset gives you information about a marketing campaign of a financial institution in which can be analysed in order to find ways to look for future strategies in order to improve future marketing campaigns for the bank.\n",
        "\n",
        "The target variable is called 'deposit' which describes if a person has subscribed to a term deposit (German: \"Termineinlage\", more information: https://www.investopedia.com/terms/t/termdeposit.asp).\n",
        "\n",
        "---\n",
        "\n",
        "Your task will be to train a neural network which will be used to predict if a person will subscribe to a term deposit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-SU7sZYYFqi"
      },
      "source": [],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFlMKv4VLUCL"
      },
      "source": [
        "# Import the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/schneiderson/ATIT2-22/main/sample_data/bank.csv')\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFfA55k57-Wx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFT2cB4FUFdq"
      },
      "source": [
        "#### Instructions\n",
        "\n",
        "This task will combine a lot of different aspect of what we have discussed in class over the past weeks.\n",
        "\n",
        "**You are expected to do:**\n",
        "\n",
        "*   **Data exploration** (6 points):\n",
        " *   Check which features are available. \n",
        " > *   Can some features directly be discarded?\n",
        " *   Check if data is messy (e.g. missing values)\n",
        " *   Check for correlation with target variable\n",
        " *   Look for outliers\n",
        " *   Class distribution\n",
        "*   **Data preparation** (6 points):\n",
        " *   Perform some data cleaning e.g.\n",
        "  >  *   Replace missing values\n",
        "  >  *   Outlier handling\n",
        "  >  *   Removal of duplicates\n",
        " *   Convert non-numeric features to numeric features\n",
        " *   Perform a 80/20 train/test split\n",
        " *   Perform feature scaling\n",
        " *   In case of class imbalance, think about how you want to deal with it. Please briefly explain your decision.\n",
        "*   **Training and model evaluation** (8 points):\n",
        " *   Please use `MLPClassifier` from `sklearn.neural_network`\n",
        " > *   The model should have 4 hidden layers with sizes hidden_layer_size=(10, 1) (parameter hidden_layer_sizes)\n",
        " > *   Set the batch_size to 64\n",
        " *   Evaluate the model performance\n",
        " > *   Calculate the accuracy and other metrics which might be helpful to evaluate the model's performance\n",
        " > *   Based on you findings, describe some measures you could take to improve the model's performance even further.\n",
        " *   Please train another model using one of the techniques we have discussed in the lectures and compare the performance to the performance achieved with the neural network.\n",
        "\n",
        "\n",
        "**For each decision you make, briefly explain your reasoning.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgao6g05XJmg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyhMjW5NhBrE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6autb4mKIBat"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGqo9JdzIi0Y"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBJCQGjRlt1X"
      },
      "source": [
        "\n",
        "#### Further tips for working on the assignment:\n",
        "\n",
        "When analyzing the model's performance, please think about what the baseline performance of the task would be and if your model performs better or not. It is quite unlikely the model will get a perfect score with the given parametrization. You can try to improve the performance by varying several hyperparameters of the model (e.g. number of hidden layers and number of neurons in a hidden layer, batch_size, training epochs, etc.). \n",
        "\n",
        "Please be aware that too many hidden layers and neurons and a large number of epochs will cause the model to train longer. If the model is too complex you might encounter time-outs in Colab.\n",
        "\n",
        "If the number of epochs is too low, sklearn will show a warning that the model has not yet converged."
      ]
    }
  ]
}
