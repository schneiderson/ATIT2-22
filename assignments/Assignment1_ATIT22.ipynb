{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schneiderson/ATIT2-22/blob/main/assignments/Assignment1_ATIT22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcQsDO5sdYwY"
      },
      "source": [
        "# ASSIGNMENT 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLb9yMmadb7Q"
      },
      "source": [
        "### Details\n",
        "\n",
        "The assignment consists of two parts:\n",
        "- Linear regression\n",
        "- Logistic regression\n",
        "\n",
        "The tasks are described throughout this notbook. Please implement what is described in the tasks and provide a written answer (in English or German) where it is required. You are allowed to add new cells to the notebook if it makes it easier for you. However, please do not remove any existing cells.\n",
        "\n",
        "\n",
        "\n",
        "### Handing in\n",
        "\n",
        "Please download the notebook as .ipynb file and upload the file to the assignment in MS teams.\n",
        "You are allowed to submit several times. The last submission *before* the deadline is what will be graded. Late submissions will get a penalty as discussed in the lecture.\n",
        "\n",
        "\n",
        "### Finally...\n",
        "\n",
        "have fun and best of luck!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Sidenote*:\n",
        "\n",
        "*In case you are unsure about what to do (e.g. due to unclear/ambiguous task description), please feel free to ask questions! (either in the next lecture or via teams/email) If you feel like you do have to make assumptions while solving the task, please describe the assumption you are making.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFLxxPqdRkh"
      },
      "source": [
        "## Import statements\n",
        "\n",
        "---\n",
        "\n",
        "Importing all required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1lr1zjdLym"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import r2_score, accuracy_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJOywxU7vtMv"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8emMOB-uvxwL"
      },
      "source": [
        "## Task\n",
        "Your task is to do a **linear regression** on the **weather history dataset**.\n",
        "This dataset contains historical data of a Hungarian city over the period of ten years (between 2006-2016).\n",
        "\n",
        "We will first load the dataset and then call the head() method on the loaeded dataframe to look at some examples in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zm6SPEdfur-"
      },
      "source": [
        "df_1 = pd.read_csv('https://github.com/schneiderson/ATIT2-22/raw/main/sample_data/weatherHistory.csv', sep=\",\")\n",
        "df_1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GPYH63TgsKU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In linear regression an attribute is a **good predictor** if there is **a correlation** between the independent variable (x: some attribute of the weather) and the independent variable (y: temperature).\n",
        "\n",
        "Check which numeric attributes have a correlation with the temperature. To achieve this you can either plot the graph and check the correlation visually (using the scatter function below). Alternatively, you can use **sns.pairplot(df_1)** to plot combinations of different variables.\n",
        "\n",
        "If the correlation is not strong it will be hard to spot in a graph. In this case it is best to use pandas **df_1.corr()** function to dispaly the correlation values in table format.\n",
        "\n",
        "(optional: you can print the correlation matrix with a heatmap from the seaborn library. sns.heatmap(df_1, annot=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.columns"
      ],
      "metadata": {
        "id": "rVm0lEvvZZ0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KbFfhsgY7O"
      },
      "source": [
        "def scatter(column):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(df_1[column], df_1['Temperature (C)'])\n",
        "    plt.title(column+' vs Temperature (C)')\n",
        "    plt.ylabel('Temperature (C)')\n",
        "    plt.xlabel(column)\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlYu7ZDrjSFG"
      },
      "source": [
        "## Data exploration\n",
        "\n",
        "---\n",
        "\n",
        "Plot the four attributes with the highest correlation to the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rd45sbngY92"
      },
      "source": [
        "# plot the four attributes with highest correlation\n",
        "# scatter(\"colum_name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ9vYnakjlPX"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Use one of the attributes with the highest correlation (**appart from \"Apparent Temperature (C)\"**) and train a linear regression model.\n",
        "\n",
        "Before training, split the dataset in training and test data. (80%, 20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOJJI79CgZAO"
      },
      "source": [
        "# use train_test_split method from sklearn.model_selection library to split data in training and testing data\n",
        "\n",
        "np.random.seed(0) # setting the seed will make the \"random\" split deterministic (more reliable and comparable results)\n",
        "\n",
        "# hint: it should look something like this:\n",
        "# df_1_train, df_1_test = train_test_split(<?>, train_size = 0.8, test_size = 0.2, random_state = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr2mpYArk7Vr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Do feature scaling on the numerical independant variables for both the training dataset and the test dataset.\n",
        "\n",
        "Use fit_transform() on the training dataset and transform() on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7FQMO8LgZCu"
      },
      "source": [
        "# use MinMaxScaler from sklearn.preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# scaler.fit_transform(<training_data>)\n",
        "# scaler.transform(<test_data>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJN_yMytQaK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Can you explain why you should not use fit_transform on both datasets? (Hint: \n",
        "think about what training and test data represent if you train a model to solve a real problem where future predictions are made on **unseen data**.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSeC87wtUT1"
      },
      "source": [
        "**--> your answer here...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LajtIUXPmLoC"
      },
      "source": [
        "## Model training\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Train a linear regression model on the training data. Use the attribute which you have identified has the highest correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GK5x7CvgZFO"
      },
      "source": [
        "# use LinearRegression class from sklearn_linear_model \n",
        "lm = LinearRegression()\n",
        "\n",
        "# we need to reshape the array because sklearn LinearRegression expects arrays in the shape of (n, f), \n",
        "# where f is the number of features we want to train on.\n",
        "x_df_1_train = df_1_train['<column_name?>'].values.reshape(-1, 1)\n",
        "y_df_1_train = df_1_train['Temperature (C)'].values.reshape(-1, 1)\n",
        "\n",
        "lm.fit(<x>, <y>)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzcUJ0QfluZH"
      },
      "source": [
        "## Predictions\n",
        "\n",
        "---\n",
        "\n",
        "Make predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAtVtFtagZHo"
      },
      "source": [
        "# reshape the test data just as you've done it above with the test data\n",
        "x_df_1_test = \n",
        "y_df_1_test =\n",
        "\n",
        "# then pass the data to the linear regression model to make predictions\n",
        "y_df_1_predicted = lm.predict(x_df_1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8whcc3IqLhT"
      },
      "source": [
        "(optional: use a goodness of fit metric like r2_score to check how good the regression is)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkOSAa1kl-d2"
      },
      "source": [
        "r2_score(y_df_1_test, y_df_1_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-0iF5WotCX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Plot true values and calculated regression line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNoIeIvinFrm"
      },
      "source": [
        "plt.scatter(x_df_1_test, y_df_1_test, color='black')\n",
        "plt.plot(x_df_1_test, y_df_1_predicted, color='blue', linewidth=3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you think of ways to train the model to improve the model's predictions?"
      ],
      "metadata": {
        "id": "zgr428golSt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--> your answer here...**"
      ],
      "metadata": {
        "id": "hRSllJx2laFg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0JZmShTU7ns"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iCh5wKYvoer"
      },
      "source": [
        "# Logistic regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtGjR-Ymwazh"
      },
      "source": [
        "## Task\n",
        "This dataset contains information about halloween candy. The dataset contains several features e.g. fruity, caramel, peanutyalmondy, nougate etc.. Your task is to use logistic regression and find out which feature is best to **predict if a candy is chocolate or not**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Cfmc2fyXvh"
      },
      "source": [
        "df_2 = pd.read_csv('https://github.com/schneiderson/ATIT2-22/raw/main/sample_data/candy_encoded.csv', sep=';')\n",
        "df_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJA4FmmPNCbo"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please plot a pairplot of the input varialbes using **sns.pairplot(df, hue='chocolate')** (creating the plot might take a short moment). The resulting graphs can tell you about the relation of some input variables and the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnBbRiYrNBep"
      },
      "source": [
        "sns.pairplot(df_2, hue='chocolate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFGSZ-J_SaiR"
      },
      "source": [
        "Take a close look at the graphs shown in this plot and try to interpret them.\n",
        "\n",
        "Based on these plots, which variables might be most useful to predict whether a candy is made of (or contains) chocolate? Please briefly elaborate how you arrive at your conclusion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tUEii-bSwat"
      },
      "source": [
        "**--> your answer here...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgjiyNJV35aX"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "---\n",
        "\n",
        "First we encode the **\"chocolate\"** feature. At this point the feature is a column containing texts either **\"yes\" or \"no\"**. What we want is a **numerical feature**. Hence, we can use a **Label Encoder** to transform the column to a binary encoded column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ2yF3JxzSd_"
      },
      "source": [
        "le = LabelEncoder()\n",
        "df_2['chocolate'] = le.fit_transform(df_2['chocolate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6jBnwbJ4PyR"
      },
      "source": [
        "Do a train test split, just like in the previous task. (80/20 train/test split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzIDD06Y0Qeq"
      },
      "source": [
        "# do a train test split like you've done in the previous task\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8DpLkcj4ZHa"
      },
      "source": [
        "Do feature scaling for the numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6azIi6Lgyr4s"
      },
      "source": [
        "scaler2 = MinMaxScaler()\n",
        "# do feature scaling like in the previous task\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHLdcK8a4i9V"
      },
      "source": [
        "## Model training\n",
        "\n",
        "---\n",
        "\n",
        "Fit the LogisticRegression model to the training data. Use the one feature that you think will produce the best result (hint: the pairplot might give you an idea which feature that might be)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvRRdVu0u53"
      },
      "source": [
        "# we need to reshape the array because sklearn LogisticRegression expects arrays in the shape of (n, f), \n",
        "# where f is the number of features we want to train on. (Check the previous task for reference)\n",
        "x_df_2_train = \n",
        "y_df_2_train = \n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_df_2_train, y_df_2_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmxXscLn4sms"
      },
      "source": [
        "## Predictions and model evaluation\n",
        "\n",
        "---\n",
        "\n",
        "Evaluate the accuracy, precision and recall metrics on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCAxO7692hAP"
      },
      "source": [
        "x_df_2_test = \n",
        "y_df_2_test = \n",
        "\n",
        "y_df_2_predictions = logreg.predict(x_df_2_test) # generate predictions\n",
        "\n",
        "print('Accuracy: {}'.format(accuracy_score(y_df_2_test, y_df_2_predictions)))\n",
        "print('Precision: {}'.format(precision_score(y_df_2_test, y_df_2_predictions)))\n",
        "print('Recall: {}'.format(recall_score(y_df_2_test, y_df_2_predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjXmHJTb-uXp"
      },
      "source": [
        "Based on these three metrics, try to discuss which result is best under which circumstances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ-arut3-9uj"
      },
      "source": [
        "**--> your answer here...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoU-01h273ze"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall from the lecture: We can do linear and logistic regression on multiple features. \n",
        "\n",
        "Does the performance of the logistic regression model improve if you use a combination of several features?\n",
        "\n",
        "Please train another logistic regression model and analyse its performance to support your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slmTD5b_8tEP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}